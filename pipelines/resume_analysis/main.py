import logging
from sqlalchemy.ext.asyncio import AsyncSession
from shared.db.connection import get_db


from shared.config import settings
from shared.schema.document import (
    ResumeAnalyzeRequest,
    ResumeAnalyzeResponse,
    PortfolioAnalyzeRequest,
    PortfolioAnalyzeResponse,
)

from .domain.models.document import DocumentType
from .domain.interface.adapter_interfaces import AnalystAgent

# Application Service
from .application.services.report import ApplicationAnalyzer

# Infrastructure (Persistence)
from .infrastructure.persistence.doc_repository import SqlAlchemyDocRepository
from .infrastructure.persistence.job_repository import SqlAlchemyJobRepository

# Infrastructure (Adapters)
from .infrastructure.adapters.storage.s3_storage import S3FileStorage
from .infrastructure.adapters.parser.pdf_extractor import PyPdfExtractor
from .infrastructure.adapters.llm.ai_agent.graph import LLMAnalyst
from .infrastructure.adapters.llm.mock_agent import MockAnalyst

logger = logging.getLogger(__name__)


async def run_resume_analysis(request: ResumeAnalyzeRequest) -> ResumeAnalyzeResponse:
    """
    ì´ë ¥ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    target_doc_type = DocumentType.RESUME
    analyzer = None

    # --- [Step 1] ë°ì´í„° ì¤€ë¹„ (ì„¸ì…˜ 1) ---
    async for session in get_db():
        analyzer = await _create_analyzer(session)
        job_info, target_text = await analyzer.prepare_analysis_data(
            user_id=int(request.user_id),
            job_id=int(request.job_posting_id),
            target_doc_type=target_doc_type,
        )
        # ì´ë ¥ì„œë¥¼ ë‹¤ìš´ë¡œë“œ/ì¶”ì¶œí–ˆë‹¤ë©´ ìƒíƒœê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì»¤ë°‹
        await session.commit()
        break  # DB ì„¸ì…˜ ì¦‰ì‹œ ë°˜ë‚©

    if not analyzer:
        raise RuntimeError("Failed to override analyzer from DB session")

    # --- [Step 2] AI ì¶”ë¡  ëŒ€ê¸° (DB ì»¤ë„¥ì…˜ ì—†ìŒ) ---
    # DB ì„¸ì…˜ì´ ë°˜í™˜ëœ ìƒíƒœì—ì„œ ëŠë¦° ì‘ì—… ì§„í–‰
    report = await analyzer.run_ai_analysis(
        job_info=job_info,
        target_text=target_text,
        target_doc_type=target_doc_type,
    )

    # --- [Step 3] ìµœì¢… ì‘ë‹µ í¬ë§·íŒ… ë°˜í™˜ ---
    return analyzer.format_resume_response(report, int(request.user_id))


async def run_portfolio_analysis(
    request: PortfolioAnalyzeRequest,
) -> PortfolioAnalyzeResponse:
    """
    í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    target_doc_type = DocumentType.PORTFOLIO
    analyzer = None

    # --- [Step 1] ë°ì´í„° ì¤€ë¹„ (ì„¸ì…˜ 1) ---
    async for session in get_db():
        analyzer = await _create_analyzer(session)
        job_info, target_text = await analyzer.prepare_analysis_data(
            user_id=int(request.user_id),
            job_id=int(request.job_posting_id),
            target_doc_type=target_doc_type,
        )
        await session.commit()
        break

    if not analyzer:
        raise RuntimeError("Failed to override analyzer from DB session")

    # --- [Step 2] AI ì¶”ë¡  ëŒ€ê¸° (DB ì»¤ë„¥ì…˜ ì—†ìŒ) ---
    report = await analyzer.run_ai_analysis(
        job_info=job_info,
        target_text=target_text,
        target_doc_type=target_doc_type,
    )

    # --- [Step 3] ìµœì¢… ì‘ë‹µ í¬ë§·íŒ… ë°˜í™˜ ---
    return analyzer.format_portfolio_response(report, int(request.user_id))


async def _create_analyzer(session: AsyncSession) -> ApplicationAnalyzer:
    """
    ApplicationAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì˜ì¡´ì„± ì£¼ì…
    """
    # 1. LLM & Agent
    agent: AnalystAgent

    # settings.use_mockê°€ Trueì¸ ê²½ìš° Mock Agent ì‚¬ìš©
    if getattr(settings, "use_mock", False):
        logger.info("ğŸ¤– Initializing Mock Analyst Agent")
        agent = MockAnalyst()
    else:
        # LLM ì„¤ì •ì„ ë¬¸ìì—´ë¡œ ì „ë‹¬ (Runtime Loading)
        llm_provider = getattr(settings, "LLM_PROVIDER", "openai")

        if llm_provider == "gemini":
            model_name = getattr(settings, "GOOGLE_MODEL", "gemini-1.5-flash")
            logger.info(f"ğŸ¤– Initializing Analyst Agent with Gemini ({model_name})")
        elif llm_provider == "vllm":
            model_name = getattr(settings, "VLLM_MODEL", "Qwen/Qwen3-32B-FP8")
            logger.info(f"ğŸ¤– Initializing Analyst Agent with vLLM ({model_name})")
        else:
            model_name = getattr(settings, "OPENAI_MODEL", "gpt-4o")
            logger.info(f"ğŸ¤– Initializing Analyst Agent with OpenAI ({model_name})")

        # LLMAnalyst ì´ˆê¸°í™” (ê°ì²´ ëŒ€ì‹  ì„¤ì •ê°’ ì „ë‹¬)
        agent = LLMAnalyst(model_name=model_name, model_provider=llm_provider)

    # 2. Infrastructure Adapters
    job_repo = SqlAlchemyJobRepository(session)
    doc_repo = SqlAlchemyDocRepository(session)
    file_storage = S3FileStorage()
    extractor = PyPdfExtractor()

    # 3. Service Assembly
    return ApplicationAnalyzer(
        job_repo=job_repo,
        doc_repo=doc_repo,
        file_storage=file_storage,
        extractor=extractor,
        agent=agent,
    )
