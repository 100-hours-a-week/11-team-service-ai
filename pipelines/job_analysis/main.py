import logging

from shared.schema.job_posting import (
    JobPostingAnalyzeRequest,
    JobPostingAnalyzeResponse,
    JobPostingDeleteResponse,
)
from .application.services.extraction_service import JobExtractionService
from .infrastructure.adapters.crawling.router import DynamicRoutingCrawler
from .infrastructure.adapters.llm.job_extractor import OpenAiJobExtractor

from shared.config import settings
from .infrastructure.adapters.llm.mock_extractor import MockJobExtractor

logger = logging.getLogger(__name__)


# TODO: ê³µê³ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬í˜„, ë²¡í„°dbì—ë§Œ ê³µê³  ì €ìž¥
async def run_pipeline(request: JobPostingAnalyzeRequest) -> JobPostingAnalyzeResponse:
    """
    í¬ë¡¤ë§ ë° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
    """
    # ì„¤ì •ì— ë”°ë¼ Extractor ì£¼ìž… ê²°ì •
    extractor_impl = MockJobExtractor() if settings.use_mock else OpenAiJobExtractor()

    service = JobExtractionService(
        crawler=DynamicRoutingCrawler(), extractor=extractor_impl
    )
    return await service.extract_job_data(request.url)


# TODO: ì‚­ì œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„, ë²¡í„°dbì— ì €ìž¥ëœ ë‚´ìš©ë§Œ ì‚­ì œ
async def delete_pipeline(job_posting_id: int) -> JobPostingDeleteResponse:
    """
    Job Posting Deletion Pipeline Entrypoint
    """
    logger.info(f"ðŸš€ [Pipeline Start] Delete Job Posting ID: {job_posting_id}")
    return JobPostingDeleteResponse(deleted_id=job_posting_id)
