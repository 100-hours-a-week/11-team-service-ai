from playwright.sync_api import Page
from ..base import BasePlaywrightCrawler
import logging

logger = logging.getLogger(__name__)


class WantedCrawler(BasePlaywrightCrawler):
    """
    ÏõêÌã∞Îìú(Wanted) Ï†ÑÏö© ÌÅ¨Î°§Îü¨.

    ÌååÏã± ÎåÄÏÉÅ DOM Í≤ΩÎ°ú:
        .JobContent_JobContent__Qb6DR                                   (Î£®Ìä∏)
            ‚îú‚îÄ‚îÄ .JobHeader_JobHeader__TZkW3                             ‚Üí Í≥µÍ≥† Ìó§Îçî
            ‚îî‚îÄ‚îÄ .JobContent_descriptionWrapper__RMlfm                  (Î≥∏Î¨∏ ÎûòÌçº)
                  ‚îú‚îÄ‚îÄ .JobDescription_JobDescription__s2Keo             ‚Üí Í≥µÍ≥† Î≥∏Î¨∏
                  ‚îú‚îÄ‚îÄ .JobDueTime_JobDueTime__yvhtg                    ‚Üí Ï†ëÏàò Í∏∞Í∞Ñ
                  ‚îî‚îÄ‚îÄ .JobWorkPlace_JobWorkPlace__xPlGe
                        ‚îî‚îÄ‚îÄ ...map__24PDM
                              ‚îî‚îÄ‚îÄ ...map__location__6pp2d              ‚Üí Í∑ºÎ¨¥ÏßÄ
    """

    _ROOT = ".JobContent_JobContent__Qb6DR"
    _WRAPPER = f"{_ROOT} .JobContent_descriptionWrapper__RMlfm"

    def _parse_page(self, page: Page) -> str:
        # ÏõêÌã∞ÎìúÎäî SPA ‚Äî Î£®Ìä∏ Ïª®ÌÖåÏù¥ÎÑàÍ∞Ä Î†åÎçîÎßÅÎê† ÎïåÍπåÏßÄ ÎåÄÍ∏∞
        try:
            page.wait_for_selector(self._ROOT, timeout=10000)
        except Exception:
            logger.warning(
                f"‚ö†Ô∏è Failed to load page content from {page.url} (Title: {page.title()})"
            )
            if "wanted" not in page.url:
                logger.error(f"üö® Suspicious Page Content (Bot Block?): {page.title()}")

        sections = [
            self._extract_header(page),
            self._extract_description(page),
            self._extract_due_time(page),
            self._extract_workplace(page),
        ]

        return "\n\n".join(s for s in sections if s)

    # ‚îÄ‚îÄ ÏÑπÏÖòÎ≥Ñ Ï∂îÏ∂ú Î©îÏÑúÎìú ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _extract_header(self, page: Page) -> str:
        """Í≥µÍ≥† Ìó§Îçî"""
        return self._extract_section(page, f"{self._ROOT} .JobHeader_JobHeader__TZkW3")

    def _extract_description(self, page: Page) -> str:
        """Í≥µÍ≥† Î≥∏Î¨∏ ‚Äî "ÏÉÅÏÑ∏Ï†ïÎ≥¥ ÎçîÎ≥¥Í∏∞" Î≤ÑÌäºÏù¥ ÏûàÏúºÎ©¥ ÌÅ¥Î¶≠ ÌõÑ Ï†ÑÏ≤¥ Î≥∏Î¨∏ Ï∂îÏ∂ú"""
        description_selector = (
            f"{self._WRAPPER} .JobDescription_JobDescription__s2Keo"
        )
        wrapper_selector = (
            f"{description_selector}"
            " .JobDescription_JobDescription__paragraph__wrapper__WPrKC"
        )

        # wrapper ÎÇ¥Î∂Ä Î≤ÑÌäº(ÎçîÎ≥¥Í∏∞)Ïù¥ ÏûàÏúºÎ©¥ ÌÅ¥Î¶≠ÌïòÏó¨ Ï†ÑÏ≤¥ Î≥∏Î¨∏ ÌôïÏû•
        button_locator = page.locator(f"{wrapper_selector} button")
        if button_locator.count() > 0:
            button_locator.first.click()
            # ÌÅ¥Î¶≠ ÌõÑ Î≤ÑÌäºÏù¥ Ï†úÍ±∞Îê† ÎïåÍπåÏßÄ ÎåÄÍ∏∞ (ÌôïÏû• ÏôÑÎ£å ÏãúÏ†ê)
            try:
                button_locator.first.wait_for(state="hidden", timeout=3000)
            except Exception:
                logger.warning("‚ö†Ô∏è 'ÎçîÎ≥¥Í∏∞' Î≤ÑÌäº Ïà®ÍπÄ ÎåÄÍ∏∞ ÌÉÄÏûÑÏïÑÏõÉ, ÌòÑÏû¨ ÏÉÅÌÉúÎ°ú ÏßÑÌñâ.")
            logger.info("‚úÖ Clicked 'ÎçîÎ≥¥Í∏∞' button in JobDescription")

        return self._extract_section(page, description_selector)

    def _extract_due_time(self, page: Page) -> str:
        """Ï†ëÏàò Í∏∞Í∞Ñ"""
        return self._extract_section(
            page, f"{self._WRAPPER} .JobDueTime_JobDueTime__yvhtg"
        )

    def _extract_workplace(self, page: Page) -> str:
        """Í∑ºÎ¨¥ÏßÄ"""
        return self._extract_section(
            page,
            f"{self._WRAPPER} .JobWorkPlace_JobWorkPlace__xPlGe"
            " .JobWorkPlace_JobWorkPlace__map__24PDM"
            " .JobWorkPlace_JobWorkPlace__map__location__6pp2d",
        )

    # ‚îÄ‚îÄ Í≥µÌÜµ Ìó¨Ìçº ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _extract_section(self, page: Page, selector: str) -> str:
        """Îã®Ïùº ÏÖÄÎ†âÌÑ∞ÏóêÏÑú ÌÖçÏä§Ìä∏Î•º Ï∂îÏ∂úÌïòÎäî Í≥µÌÜµ Ìó¨Ìçº"""
        if page.locator(selector).count() > 0:
            text = self._clean_html(page.locator(selector).inner_html())
            logger.info(f"‚úÖ Extracted: {selector}")
            return text

        logger.warning(f"‚ö†Ô∏è Section not found: {selector}")
        return ""
