import logging
from typing import Optional
from langchain_core.language_models import BaseChatModel
from langchain_core.output_parsers import PydanticOutputParser
from ....domain.interface.extractor import JobDataExtractor
from ....domain.models.job_data import ExtractedJobData
from .prompts import get_job_extraction_prompt

logger = logging.getLogger(__name__)


class LLMJobExtractor(JobDataExtractor):
    """
    LLM(LangChain)ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš© ê³µê³  ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì–´ëŒ‘í„°.
    íŠ¹ì • LLM êµ¬í˜„ì²´ì— ì˜ì¡´í•˜ì§€ ì•Šê³  BaseChatModelì„ ì£¼ì…ë°›ì•„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """

    def __init__(self, llm: BaseChatModel):
        self.llm = llm

        # Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì„œ ì„¤ì •
        self.parser = PydanticOutputParser(pydantic_object=ExtractedJobData)

    async def extract(self, raw_text: str) -> Optional[ExtractedJobData]:
        """
        raw_textì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ExtractedJobData ë°˜í™˜
        """
        logger.info(f"ğŸ§  Extracting job data from text ({len(raw_text)} chars)...")

        try:
            # í”„ë¡¬í”„íŠ¸ ì •ì˜
            prompt = get_job_extraction_prompt()

            # ì²´ì¸ ì—°ê²°
            chain = prompt | self.llm | self.parser

            # ì‹¤í–‰
            result = await chain.ainvoke(
                {
                    "raw_text": raw_text[:15000],  # í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ì ˆì‚­
                    # "format_instructions": self.parser.get_format_instructions(), # Removed
                }
            )

            # PydanticOutputParserëŠ” ì´ë¯¸ Pydantic ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ë°”ë¡œ ë¦¬í„´
            logger.info(
                f"âœ… Job extraction successful: {result.job_title} at {result.company_name}"
            )
            return result

        except Exception as e:
            logger.error(f"âŒ Extraction failed: {e}", exc_info=True)
            return None
