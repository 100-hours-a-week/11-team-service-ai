from abc import ABC, abstractmethod
import logging
import subprocess
from playwright.sync_api import sync_playwright, Page, Error as PlaywrightError
from bs4 import BeautifulSoup
from fastapi import HTTPException

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class BasePlaywrightCrawler(ABC):
    """
    ëª¨ë“  Playwright ê¸°ë°˜ í¬ë¡¤ëŸ¬ì˜ ë¶€ëª¨ í´ë˜ìŠ¤.
    ê³µí†µì ì¸ ë¸Œë¼ìš°ì € ì‹¤í–‰ ë° ì¢…ë£Œ ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        self._ensure_browser_installed()
        self.user_agent = (
             "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
             "AppleWebKit/537.36 (KHTML, like Gecko) "
             "Chrome/120.0.0.0 Safari/537.36"
        )

    def _ensure_browser_installed(self):
        """ë¸Œë¼ìš°ì € ì„¤ì¹˜ í™•ì¸ ë° ìë™ ì„¤ì¹˜"""
        try:
            subprocess.run(
                ["playwright", "--version"],
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.info("ğŸ”§ Playwright not found or browsers missing. Installing chromium...")
            try:
                subprocess.run(["playwright", "install", "chromium"], check=True)
                logger.info("âœ… Playwright chromium installed successfully.")
            except Exception as e:
                logger.error(f"âŒ Failed to install Playwright browsers: {e}")
                raise RuntimeError("Could not install Playwright browsers.") from e

    def fetch(self, url: str) -> str:
        """
        ê³µí†µ í…œí”Œë¦¿ ë©”ì„œë“œ: ë¸Œë¼ìš°ì € ì‹¤í–‰ -> í˜ì´ì§€ ì´ë™ -> (ìì‹ í´ë˜ìŠ¤ ë¡œì§) -> í…ìŠ¤íŠ¸ ë°˜í™˜
        """
        logger.info(f"ğŸŒ [Playwright] Crawling URL: {url}")
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=False)
                context = browser.new_context(
                    user_agent=self.user_agent,
                    viewport={"width": 1920, "height": 1080}
                )
                page = context.new_page()

                # ì†ë„ ìµœì í™”: ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤(ì´ë¯¸ì§€, í°íŠ¸ ë“±) ë¡œë”© ì°¨ë‹¨
                def block_resources(route):
                    if route.request.resource_type in ["image", "media", "font", "stylesheet"]:
                        route.abort()
                    else:
                        route.continue_()

                # ëª¨ë“  ìš”ì²­ì— ëŒ€í•´ ì¸í„°ì…‰í„° ë“±ë¡
                page.route("**/*", block_resources)
                
                # ê³µí†µ í˜ì´ì§€ ì´ë™ ë¡œì§ (íƒ€ì„ì•„ì›ƒì€ ë„‰ë„‰íˆ ì£¼ë˜, ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ë§‰ì•„ë‘¬ì„œ ë¹¨ë¦¬ ëë‚¨)
                page.goto(url, timeout=60000, wait_until="domcontentloaded")
                
                # ìì‹ í´ë˜ìŠ¤ë³„ êµ¬ì²´ì ì¸ íŒŒì‹± ë¡œì§ ì‹¤í–‰ (Hook)
                result_text = self._parse_page(page)
                
                browser.close()
                return result_text

        except PlaywrightError as e:
            logger.error(f"âŒ Playwright error: {e}")
            raise HTTPException(status_code=400, detail=f"Crawling failed: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ Unexpected error: {e}")
            raise HTTPException(status_code=500, detail=f"Internal crawler error: {str(e)}")

    @abstractmethod
    def _parse_page(self, page: Page) -> str:
        """
        ê° ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ê°€ êµ¬ì²´ì ìœ¼ë¡œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” íŒŒì‹± ë¡œì§.
        Page ê°ì²´ë¥¼ ë°›ì•„ì„œ ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        pass

    def _clean_html(self, html_content: str) -> str:
        """HTML ì •ì œ í—¬í¼ ë©”ì„œë“œ (BeautifulSoup í™œìš©)"""
        soup = BeautifulSoup(html_content, "html.parser")
        
        unwanted_tags = ["script", "style", "noscript", "header", "footer", "nav", "aside", "form"]
        for tag in soup(unwanted_tags):
            tag.decompose()

        text = soup.get_text(separator="\n", strip=True)
        import re
        text = re.sub(r"\n\s*\n", "\n\n", text)
        return text.strip()
