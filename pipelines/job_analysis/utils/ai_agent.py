"""AI Agent utilities for decision making in normalization and duplicate detection"""

import logging
from typing import Optional
from langchain_openai import ChatOpenAI
from pydantic import SecretStr
from shared.config import settings

logger = logging.getLogger(__name__)


class AIAgent:
    """AI Agent for making intelligent decisions using LLM"""

    def __init__(self):
        if not settings.use_mock:
            self.llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0,
                api_key=(
                    SecretStr(settings.OPENAI_API_KEY)
                    if settings.OPENAI_API_KEY
                    else None
                ),
            )

    async def is_same_company(self, raw_name: str, normalized_name: str) -> bool:
        # Mock ëª¨ë“œ: OpenAI í˜¸ì¶œ ì—†ì´ ê°„ë‹¨í•œ ë¬¸ìì—´ ë¹„êµ
        if settings.use_mock:
            is_same = raw_name.lower().replace(
                " ", ""
            ) == normalized_name.lower().replace(" ", "")
            logger.info(
                f"[Mock] is_same_company: '{raw_name}' vs '{normalized_name}' â†’ {is_same}"
            )
            return is_same
        """
        ë‘ íšŒì‚¬ëª…ì´ ê°™ì€ íšŒì‚¬ë¥¼ ê°€ë¦¬í‚¤ëŠ”ì§€ LLMìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            raw_name: ì›ë³¸ íšŒì‚¬ëª…
            normalized_name: ì •ê·œí™”ëœ íšŒì‚¬ëª… (í›„ë³´)

        Returns:
            True if same company, False otherwise
        """
        prompt = f"""ë‹¤ìŒ ë‘ íšŒì‚¬ëª…ì´ ê°™ì€ íšŒì‚¬ë¥¼ ê°€ë¦¬í‚¤ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

íšŒì‚¬ëª… A: {raw_name}
íšŒì‚¬ëª… B: {normalized_name}

ê°™ì€ íšŒì‚¬ë¼ë©´ "YES", ë‹¤ë¥¸ íšŒì‚¬ë¼ë©´ "NO"ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
ì•½ì–´, ì˜ë¬¸/í•œê¸€ í‘œê¸° ì°¨ì´, ë²•ì¸ í˜•íƒœ ì°¨ì´ëŠ” ê°™ì€ íšŒì‚¬ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
- "ì¹´ì¹´ì˜¤" vs "Kakao" â†’ YES
- "ë„¤ì´ë²„" vs "NAVER" â†’ YES
- "ì‚¼ì„±ì „ì" vs "ì‚¼ì„±SDI" â†’ NO

ë‹µë³€:"""

        try:
            response = await self.llm.ainvoke(prompt)
            answer = str(response.content).strip().upper()
            is_same = answer == "YES"

            logger.info(
                f"ğŸ¤– AI Agent decision: '{raw_name}' vs '{normalized_name}' â†’ {answer}"
            )
            return is_same

        except Exception as e:
            logger.error(f"âŒ AI Agent error: {e}. Defaulting to False (conservative)")
            return False

    async def is_same_skill(self, raw_name: str, normalized_name: str) -> bool:
        """
        ë‘ ìŠ¤í‚¬ëª…ì´ ê°™ì€ ê¸°ìˆ ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ LLMìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            raw_name: ì›ë³¸ ìŠ¤í‚¬ëª…
            normalized_name: ì •ê·œí™”ëœ ìŠ¤í‚¬ëª… (í›„ë³´)

        Returns:
            True if same skill, False otherwise
        """
        # Mock ëª¨ë“œ: OpenAI í˜¸ì¶œ ì—†ì´ ê°„ë‹¨í•œ ë¬¸ìì—´ ë¹„êµ
        if settings.use_mock:
            is_same = raw_name.lower().replace(
                " ", ""
            ) == normalized_name.lower().replace(" ", "")
            logger.info(
                f"[Mock] is_same_skill: '{raw_name}' vs '{normalized_name}' â†’ {is_same}"
            )
            return is_same

        prompt = f"""ë‹¤ìŒ ë‘ ê¸°ìˆ /ìŠ¤í‚¬ëª…ì´ ê°™ì€ ê¸°ìˆ ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ìŠ¤í‚¬ A: {raw_name}
ìŠ¤í‚¬ B: {normalized_name}

ê°™ì€ ê¸°ìˆ ì´ë¼ë©´ "YES", ë‹¤ë¥¸ ê¸°ìˆ ì´ë¼ë©´ "NO"ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
ì•½ì–´, ëŒ€ì†Œë¬¸ì ì°¨ì´, ë²„ì „ ì°¨ì´ëŠ” ê°™ì€ ê¸°ìˆ ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
- "JavaScript" vs "Javascript" â†’ YES
- "React.js" vs "React" â†’ YES
- "Python3" vs "Python" â†’ YES
- "Vue" vs "React" â†’ NO
- "Docker" vs "Kubernetes" â†’ NO

ë‹µë³€:"""

        try:
            response = await self.llm.ainvoke(prompt)
            answer = str(response.content).strip().upper()
            is_same = answer == "YES"

            logger.info(
                f"ğŸ¤– AI Agent decision: '{raw_name}' vs '{normalized_name}' â†’ {answer}"
            )
            return is_same

        except Exception as e:
            logger.error(f"âŒ AI Agent error: {e}. Defaulting to False (conservative)")
            return False

    async def is_same_job_posting(self, new_data: dict, existing_data: dict) -> bool:
        """
        ë‘ ì±„ìš© ê³µê³ ê°€ ê°™ì€ ê³µê³ ì¸ì§€ LLMìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            new_data: ì‹ ê·œ ê³µê³  ë°ì´í„° (job_title, company ë“±)
            existing_data: ê¸°ì¡´ ê³µê³  ë°ì´í„° (job_title, company ë“±)

        Returns:
            True if same job posting, False otherwise
        """
        # Mock ëª¨ë“œ: OpenAI í˜¸ì¶œ ì—†ì´ ê°„ë‹¨í•œ ë¹„êµ
        if settings.use_mock:
            is_same = (
                new_data.get("company", "").lower()
                == existing_data.get("company", "").lower()
                and new_data.get("job_title", "").lower()
                == existing_data.get("job_title", "").lower()
            )
            logger.info(f"[Mock] is_same_job_posting â†’ {is_same}")
            return is_same

        prompt = f"""ë‹¤ìŒ ë‘ ì±„ìš© ê³µê³ ê°€ ê°™ì€ ê³µê³ ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

[ê³µê³  A]
- íšŒì‚¬: {new_data.get('company', 'N/A')}
- ì§ë¬´: {new_data.get('job_title', 'N/A')}
- ì£¼ìš” ì—…ë¬´: {new_data.get('main_tasks', 'N/A')}

[ê³µê³  B]
- íšŒì‚¬: {existing_data.get('company', 'N/A')}
- ì§ë¬´: {existing_data.get('job_title', 'N/A')}
- ì£¼ìš” ì—…ë¬´: {existing_data.get('main_tasks', 'N/A')}

ê°™ì€ ì±„ìš© ê³µê³ ë¼ë©´ "YES", ë‹¤ë¥¸ ì±„ìš© ê³µê³ ë¼ë©´ "NO"ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
ê°™ì€ íšŒì‚¬ì˜ ê°™ì€ í¬ì§€ì…˜ì´ì§€ë§Œ í‘œí˜„ì´ ì•½ê°„ ë‹¤ë¥¸ ê²½ìš° ê°™ì€ ê³µê³ ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

ë‹µë³€:"""

        try:
            response = await self.llm.ainvoke(prompt)
            answer = str(response.content).strip().upper()
            is_same = answer == "YES"

            logger.info(f"ğŸ¤– AI Agent decision for job posting â†’ {answer}")
            return is_same

        except Exception as e:
            logger.error(f"âŒ AI Agent error: {e}. Defaulting to False (conservative)")
            return False


# Singleton instance
_agent_instance: Optional[AIAgent] = None


def get_ai_agent() -> AIAgent:
    """AI Agent ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = AIAgent()
    return _agent_instance
