from langchain_core.language_models.chat_models import BaseChatModel
import logging
from typing import List, Union

from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage

from .....domain.interface.adapter_interfaces import ComparisonAnalyzer
from .....domain.models.job import JobInfo
from .....domain.models.report import ComparisonReport
from .....domain.models.candidate import Candidate

from .configuration import CandidateContext, Configuration
from .state import CandidateState

from pydantic import BaseModel, Field

from .prompts import DEBATE_AGENT_PROMPT, OPENING_STATEMENT_PROMPT, FINAL_DECISION_PROMPT
from shared.utils import load_chat_model, AiResponse

logger = logging.getLogger(__name__)

class FinalDecisionOutput(BaseModel):
    strengths: str = Field(description="ë‚´ ì§€ì›ìì˜ í•µì‹¬ ê°•ì  ìš”ì•½")
    weaknesses: str = Field(description="ë‚´ ì§€ì›ìì˜ ì£¼ìš” ì•½ì  ìš”ì•½")


async def agent_me_attack(state: CandidateState, config: RunnableConfig, runtime: Runtime[CandidateContext]):
    """ë‚´ ì§€ì›ì(My Candidate) ì…ì¥ì—ì„œ ë°©ì–´ ë° ê³µê²©"""
    logger.info("ğŸ¤– Agent Me: Defending & Attacking...")

    # 1. Config & Context ë¡œë“œ
    cfg = Configuration.from_runnable_config(config)
    rtx = runtime.context # CandidateContext (job_info, candidates)

    # 2. LLM ë¡œë“œ (AiResponse structured output ì‚¬ìš©)
    llm = load_chat_model(cfg.model_name, cfg.model_provider).with_structured_output(AiResponse)

    # 3. ì •ë³´ í¬ë§·íŒ…
    job_info_text = _format_job_info(rtx.job_info)
    my_info = _format_candidate_info(rtx.my_candidate)
    comp_info = _format_candidate_info(rtx.competitor_candidate)

    # 4. ì²« í„´ì´ë©´ Opening Statement ì‚¬ìš©, ì´í›„ëŠ” Debate í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if len(state.messages) == 0:
        prompt = OPENING_STATEMENT_PROMPT
        logger.info("ğŸ“¢ Agent_Me: Opening Statement")
    else:
        prompt = DEBATE_AGENT_PROMPT
        logger.info("ğŸ’¬ Agent_Me: Responding to competitor")

    # 5. ì²´ì¸ ì‹¤í–‰
    chain = prompt | llm

    ai_response: AiResponse = await chain.ainvoke({
        "me": "Agent_Me",
        "other": "Agent_Competitor",
        "job_info": job_info_text,
        "my_candidate_info": my_info,
        "competitor_info": comp_info,
        "chat_history": state.messages
    })

    # AIMessage ìƒì„± (structured outputì˜ response í•„ë“œ ì‚¬ìš©)
    message = AIMessage(
        content=f"[Agent_Me]\n{ai_response.response}",
        name="Agent_Me"
    )
    logger.info(f"\n[Agent_Me Response]:\n{message.content}\n")
    return {"messages": [message]}


async def agent_competitor_attack(state: CandidateState, config: RunnableConfig, runtime: Runtime[CandidateContext]):
    """ê²½ìŸ ì§€ì›ì(Competitor) ì…ì¥ì—ì„œ ë°©ì–´ ë° ê³µê²©"""
    logger.info("ğŸ¤– Agent Competitor: Defending & Attacking...")

    cfg = Configuration.from_runnable_config(config)
    rtx = runtime.context

    # AiResponse structured output ì‚¬ìš©
    llm = load_chat_model(cfg.model_name, cfg.model_provider).with_structured_output(AiResponse)

    job_info_text = _format_job_info(rtx.job_info)
    my_info = _format_candidate_info(rtx.competitor_candidate)
    comp_info = _format_candidate_info(rtx.my_candidate)

    # CompetitorëŠ” í•­ìƒ ë‘ ë²ˆì§¸ ë°œì–¸ìì´ë¯€ë¡œ DEBATE_AGENT_PROMPT ì‚¬ìš©
    chain = DEBATE_AGENT_PROMPT | llm
    logger.info("ğŸ’¬ Agent_Competitor: Responding to Agent_Me")

    # ì—­í•  ë°˜ì „ (who <-> other)
    ai_response: AiResponse = await chain.ainvoke({
        "me": "Agent_Competitor",
        "other": "Agent_Me",
        "job_info": job_info_text,
        "my_candidate_info": my_info,
        "competitor_info": comp_info,
        "chat_history": state.messages
    })

    # AIMessage ìƒì„± (structured outputì˜ response í•„ë“œ ì‚¬ìš©)
    message = AIMessage(
        content=f"[Agent_Competitor]\n{ai_response.response}",
        name="Agent_Competitor"
    )
    logger.info(f"\n[Agent_Competitor Response]:\n{message.content}\n")

    # í„´ ì¹´ìš´íŠ¸ ì¦ê°€
    return {"turn_count": state.turn_count + 1, "messages": [message]}


async def check_turn(state: CandidateState):
    turn_count = state.turn_count
    logger.info(f"ğŸ”„ Current Turn: {turn_count}")

    # 3í„´(ì™•ë³µ 1.5íšŒ) ì •ë„ ì§„í–‰ í›„ ì¢…ë£Œ
    if turn_count < 3:
        return "continue"
    else:
        return "end"


async def finalize_evaluation(state: CandidateState, config: RunnableConfig, runtime: Runtime[CandidateContext]):
    """ìµœì¢… íŒì • ë° ë¦¬í¬íŠ¸ ìƒì„±"""
    logger.info("âš–ï¸ Finalizing Evaluation...")

    cfg = Configuration.from_runnable_config(config)
    rtx = runtime.context
    
    # Structured Output ì‚¬ìš© (FinalDecisionOutput)
    llm = load_chat_model(cfg.model_name, cfg.model_provider).with_structured_output(FinalDecisionOutput)
    
    job_info_text = _format_job_info(rtx.job_info)
    my_info = _format_candidate_info(rtx.my_candidate)
    comp_info = _format_candidate_info(rtx.competitor_candidate)
    
    chain = FINAL_DECISION_PROMPT | llm
    
    try:
        result: FinalDecisionOutput = await chain.ainvoke({
            "job_info": job_info_text,
            "my_candidate_info": my_info,
            "competitor_info": comp_info,
            "chat_history": state.messages
        })
        
        return {
            "strengths": result.strengths, 
            "weaknesses": result.weaknesses
        }
        
    except Exception as e:
        logger.error(f"Failed to generate structured report: {e}")
        return {
            "strengths": "ë¶„ì„ ì‹¤íŒ¨ (ì˜¤ë¥˜ ë°œìƒ)",
            "weaknesses": "ë¶„ì„ ì‹¤íŒ¨ (ì˜¤ë¥˜ ë°œìƒ)"
        }


def _format_job_info(job: JobInfo) -> str:
    return f"""
    - ì§ë¬´: {job.job_title}
    - ì£¼ìš” ì—…ë¬´: {', '.join(job.main_tasks)}
    - ê¸°ìˆ  ìŠ¤íƒ: {', '.join(job.tech_stacks)}
    - ìê²© ìš”ê±´: {', '.join(getattr(job, 'qualifications', []))}
    - ìš°ëŒ€ ì‚¬í•­: {', '.join(getattr(job, 'preferred_points', []))}
    """

def _format_candidate_info(candidate: Candidate) -> str:
    return f"""
    [Evaluation Summary]
    - í•œì¤„í‰: {candidate.evaluation.one_line_review}
    - ìƒì„¸ í”¼ë“œë°±: {candidate.evaluation.feedback_detail}
    
    [Documents Summary]
    - ì´ë ¥ì„œ ìš”ì•½: {candidate.documents.parsed_resume}
    - í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½: {candidate.documents.parsed_portfolio}
    """
