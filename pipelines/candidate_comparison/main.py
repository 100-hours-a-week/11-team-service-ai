import logging
from shared.db.connection import get_db
from shared.config import settings
from shared.schema.applicant import CompareRequest, CompareResponse

# Domain Interface
from .domain.interface.adapter_interfaces import ComparisonAnalyzer

# Application Service
from .application.services.comparison_use_case import ComparisonUseCase

# Infrastructure (Persistence)
from .infrastructure.persistence.candidate_repository import (
    SqlAlchemyCandidateRepository,
)
from .infrastructure.persistence.job_repository import SqlAlchemyJobRepository

# Infrastructure (Adapters)
from .infrastructure.adapters.llm.mock_agent import MockComparisonAnalyzer
from .infrastructure.adapters.llm.ai_agent.graph import LLMAnalyst


logger = logging.getLogger(__name__)


async def run_pipeline(request: CompareRequest) -> CompareResponse:
    """
    ì§€ì›ì ë¹„êµ íŒŒì´í”„ë¼ì¸ì˜ ë©”ì¸ ì§„ì…ì  (Async Entrypoint)
    ì™¸ë¶€(API Router ë˜ëŠ” pipeline_bridge)ì—ì„œ í˜¸ì¶œí•  ë•Œ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        request: CompareRequest
            - job_posting_id: ë¹„êµ ê¸°ì¤€ ê³µê³  ID
            - user_id: ë‚´ ì§€ì›ì ID
            - competitor: ë¹„êµ ëŒ€ìƒ ì§€ì›ì ID

    Returns:
        CompareResponse: ë¹„êµ ê²°ê³¼ (comparison_metrics, strengths_report, weaknesses_report)
    """
    logger.info(
        f"ğŸš€ [Pipeline Start] Comparing user {request.user_id} vs {request.competitor} "
        f"for job {request.job_posting_id}"
    )

    # DB ì„¸ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ (Async Generator)
    async for db_session in get_db():
        # 1. Infrastructure Layer êµ¬í˜„ì²´ ìƒì„± (Dependencies)
        candidate_repo = SqlAlchemyCandidateRepository(db_session)
        job_repo = SqlAlchemyJobRepository(db_session)

        # 2. AI Analyzer ì„ íƒ (Mock or Real)
        analyzer: ComparisonAnalyzer

        # use_mockê°€ Trueì¸ ê²½ìš° Mock Agent ì‚¬ìš©
        if getattr(settings, "use_mock", False):
            logger.info("ğŸ¤– Using Mock Comparison Analyzer")
            analyzer = MockComparisonAnalyzer()
        else:
            analyzer: LLMAnalyst
            llm_provider = getattr(settings, "LLM_PROVIDER", "openai")
            if llm_provider == "gemini":
                model_name = getattr(settings, "GOOGLE_MODEL", "gemini-3-flash-preview")
            elif llm_provider == "vllm":
                model_name = getattr(settings, "VLLM_MODEL", "Qwen/Qwen3-32B-FP8")
            else:
                model_name = getattr(settings, "OPENAI_MODEL", "gpt-4o-mini")
            
            analyzer = LLMAnalyst(model_name=model_name, model_provider=llm_provider)

        # 3. Application Serviceì— ì˜ì¡´ì„± ì£¼ì… (Wiring)
        use_case = ComparisonUseCase(
            candidate_repo=candidate_repo,
            job_repo=job_repo,
            ai_analyzer=analyzer,
        )

        # 4. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹¤í–‰ (Async)
        result = await use_case.compare_candidates(
            my_candidate_id=int(request.user_id),
            competitor_candidate_id=int(request.competitor),
            job_posting_id=int(request.job_posting_id),
        )

        # 5. íŠ¸ëœì­ì…˜ ì»¤ë°‹ (ì½ê¸° ì „ìš©ì´ì§€ë§Œ ì¼ê´€ì„± ìœ ì§€)
        await db_session.commit()

        logger.info(
            f"âœ¨ [Pipeline Complete] Comparison finished for user {request.user_id}"
        )
        return result

    raise RuntimeError("Failed to obtain database session")
